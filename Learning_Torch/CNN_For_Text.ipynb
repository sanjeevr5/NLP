{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_For_Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLw9+5ukcb5cEW0C1ZiflK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeevr5/NLP/blob/main/CNN_For_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peZiocn9tLV-"
      },
      "source": [
        "# Textual Sarcasm Detection Using CNN\n",
        "\n",
        "- Architecture Used : CNN With BPEmb embeddings(https://github.com/bheinzerling/bpemb)\n",
        "- Referring : https://chriskhanhtran.github.io/posts/cnn-sentence-classification/ including the CNN architecture image\n",
        "- @article{misra2019sarcasm,\n",
        "  title={Sarcasm Detection using Hybrid Neural Network},\n",
        "  author={Misra, Rishabh and Arora, Prahal},\n",
        "  journal={arXiv preprint arXiv:1908.07414},\n",
        "  year={2019}\n",
        "}\n",
        "- Given data is in json format and is_sarcastic will be our label and let us try to predict using the \"headline\" only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfKAvmd-Rqor"
      },
      "source": [
        "**This notebook is intended not to get good results from the architecture but a way to demonstrate how CNNs can be used with text data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuvVgF-hRuiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716ec3d3-cd01-484a-8ac6-428e9fbf9344"
      },
      "source": [
        "!head -5 ./Sarcasm_Headlines_Dataset.json"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"article_link\": \"https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5\", \"headline\": \"former versace store clerk sues over secret 'black code' for minority shoppers\", \"is_sarcastic\": 0}\r\n",
            "{\"article_link\": \"https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365\", \"headline\": \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", \"is_sarcastic\": 0}\r\n",
            "{\"article_link\": \"https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697\", \"headline\": \"mom starting to fear son's web series closest thing she will have to grandchild\", \"is_sarcastic\": 1}\r\n",
            "{\"article_link\": \"https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302\", \"headline\": \"boehner just wants wife to listen, not come up with alternative debt-reduction ideas\", \"is_sarcastic\": 1}\r\n",
            "{\"article_link\": \"https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb\", \"headline\": \"j.k. rowling wishes snape happy birthday in the most magical way\", \"is_sarcastic\": 0}\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZTplJWBUJgS",
        "outputId": "f6dff76d-e991-45ed-e028-48e75d199fcc"
      },
      "source": [
        "!head -5 ./Sarcasm_Headlines_Dataset_v2.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"is_sarcastic\": 1, \"headline\": \"thirtysomething scientists unveil doomsday clock of hair loss\", \"article_link\": \"https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205\"}\r\n",
            "{\"is_sarcastic\": 0, \"headline\": \"dem rep. totally nails why congress is falling short on gender, racial equality\", \"article_link\": \"https://www.huffingtonpost.com/entry/donna-edwards-inequality_us_57455f7fe4b055bb1170b207\"}\r\n",
            "{\"is_sarcastic\": 0, \"headline\": \"eat your veggies: 9 deliciously different recipes\", \"article_link\": \"https://www.huffingtonpost.com/entry/eat-your-veggies-9-delici_b_8899742.html\"}\r\n",
            "{\"is_sarcastic\": 1, \"headline\": \"inclement weather prevents liar from getting to work\", \"article_link\": \"https://local.theonion.com/inclement-weather-prevents-liar-from-getting-to-work-1819576031\"}\r\n",
            "{\"is_sarcastic\": 1, \"headline\": \"mother comes pretty close to using word 'streaming' correctly\", \"article_link\": \"https://www.theonion.com/mother-comes-pretty-close-to-using-word-streaming-cor-1819575546\"}\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsmSvTO_UfKs"
      },
      "source": [
        "import json\n",
        "\n",
        "def read_file(path):\n",
        "  for line in open(path, 'r'):\n",
        "    yield json.loads(line)\n",
        "\n",
        "train_data = list(read_file('./Sarcasm_Headlines_Dataset.json'))\n",
        "test_data = list(read_file('./Sarcasm_Headlines_Dataset_v2.json'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSVY80iHVAAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d970c4b-9039-40c4-baa0-64e570254f10"
      },
      "source": [
        "print('Train Data\\n\\n')\n",
        "print(train_data[:5])\n",
        "print('Test Data\\n\\n')\n",
        "print(test_data[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data\n",
            "\n",
            "\n",
            "[{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}, {'article_link': 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365', 'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", 'is_sarcastic': 0}, {'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697', 'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\", 'is_sarcastic': 1}, {'article_link': 'https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302', 'headline': 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas', 'is_sarcastic': 1}, {'article_link': 'https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb', 'headline': 'j.k. rowling wishes snape happy birthday in the most magical way', 'is_sarcastic': 0}]\n",
            "Test Data\n",
            "\n",
            "\n",
            "[{'is_sarcastic': 1, 'headline': 'thirtysomething scientists unveil doomsday clock of hair loss', 'article_link': 'https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205'}, {'is_sarcastic': 0, 'headline': 'dem rep. totally nails why congress is falling short on gender, racial equality', 'article_link': 'https://www.huffingtonpost.com/entry/donna-edwards-inequality_us_57455f7fe4b055bb1170b207'}, {'is_sarcastic': 0, 'headline': 'eat your veggies: 9 deliciously different recipes', 'article_link': 'https://www.huffingtonpost.com/entry/eat-your-veggies-9-delici_b_8899742.html'}, {'is_sarcastic': 1, 'headline': 'inclement weather prevents liar from getting to work', 'article_link': 'https://local.theonion.com/inclement-weather-prevents-liar-from-getting-to-work-1819576031'}, {'is_sarcastic': 1, 'headline': \"mother comes pretty close to using word 'streaming' correctly\", 'article_link': 'https://www.theonion.com/mother-comes-pretty-close-to-using-word-streaming-cor-1819575546'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba_Cc9d_VXHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff17f4a-430e-4a7c-cb11-0436e3082579"
      },
      "source": [
        "import numpy as np\n",
        "SEED = 43\n",
        "np.random.seed(SEED)\n",
        "train_data = np.array([(row['headline'], row['is_sarcastic']) for row in train_data])\n",
        "test_data = np.array([(row['headline'], row['is_sarcastic']) for row in test_data])\n",
        "print(f'Train shape is {train_data.shape} and test shape is {test_data.shape}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape is (26709, 2) and test shape is (28619, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07l5fxmxXapj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd276d2-6b42-4213-efe1-8630a827ee97"
      },
      "source": [
        "from collections import Counter\n",
        "print(f'Train label distribution : {Counter(train_data[:,1])}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train label distribution : Counter({'0': 14985, '1': 11724})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrfo20QrYjei"
      },
      "source": [
        "- The labels distribution are not so skewed\n",
        "- We will the use BPEmb as our embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTK6C4csZB_6"
      },
      "source": [
        "%%capture\n",
        "!pip install bpemb\n",
        "!pip install ftfy\n",
        "from bpemb import BPEmb\n",
        "bpemb_en = BPEmb(lang=\"en\", dim=300, vs = 10000) #vs will be the voacb size"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7SUth-pel63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6907f2-e497-45a0-ffae-97c7a12459b7"
      },
      "source": [
        "embeddings = bpemb_en.vectors\n",
        "embeddings = np.insert(embeddings, 0, [0] * 300, axis = 0) #Adding 300d zero vector to the embeddings\n",
        "print(embeddings.shape) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10001, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlB2Wq68cPjz"
      },
      "source": [
        "word2idx = {key : index+1 for index, key in enumerate(bpemb_en.emb.vocab.keys())}\n",
        "word2idx['<pad>'] = 0\n",
        "idx2word = {index+1 : key for index, key in enumerate(bpemb_en.emb.vocab.keys())}\n",
        "idx2word[0] = '<pad>'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A60dQaUygBX5"
      },
      "source": [
        "import ftfy #for fixing encoding issues\n",
        "\n",
        "def prepare_data(sentence, max_len = 65):\n",
        "  encoded = bpemb_en.encode(ftfy.fix_text(sentence))\n",
        "  encoded = [word2idx[token] if word2idx.get(token,0) else 1 for token in encoded]\n",
        "  encoded += [0] * (max_len - len(encoded))\n",
        "  return encoded[:max_len]\n",
        "\n",
        "train_labels = train_data[:,1].astype(int)\n",
        "test_labels = test_data[:,1].astype(int)\n",
        "\n",
        "train_encoded, test_encoded = [], []\n",
        "\n",
        "for headline, label in train_data:\n",
        "  train_encoded.append(prepare_data(headline))\n",
        "for headline, label in test_data:\n",
        "  test_encoded.append(prepare_data(headline))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Bpi4y9oxsa"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler, SequentialSampler)\n",
        "\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "train_dataset = TensorDataset(torch.tensor(train_encoded), torch.from_numpy(train_labels))\n",
        "test_dataset = TensorDataset(torch.tensor(test_encoded), torch.from_numpy(test_labels))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = 32)\n",
        "test_loader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = 32)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PELBn4mFEm_z"
      },
      "source": [
        "## CNN Architecture\n",
        "\n",
        "- We use 1D convolutions here\n",
        "\n",
        "<b> What are the differences between 1D and 2D convs? </b>\n",
        "\n",
        "- The direction matters the 2D conv kernel can travel along both x-axis and y-axis while the 1D kernel can travel along x-axis\n",
        "- Conv2D == Conv1D when kernel size has the same width as the input's width\n",
        "- Generally, 1D convs are used in text and signal processing\n",
        "\n",
        "![](https://github.com/chriskhanhtran/CNN-Sentence-Classification-PyTorch/blob/master/cnn-architecture.JPG?raw=true)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TeaF5_xFUlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c10f6e7-f6b4-47a9-e7f3-3841cbfb1008"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'This runs on {device}')\n",
        "\n",
        "class CNN_Text(nn.Module):\n",
        "\n",
        "  def __init__(self, embed, filter_sizes, num_filters, classes = 1, freeze_emb = True, drop_rate = 0.5):\n",
        "    super(CNN_Text, self).__init__()\n",
        "    self.vocab_size, self.emb_size = embed.shape\n",
        "    self.embedding = nn.Embedding.from_pretrained(embed, freeze = freeze_emb)\n",
        "    self.conv1d = nn.ModuleList([nn.Conv1d(in_channels = self.emb_size, out_channels = num_filters[i], kernel_size = filter_sizes[i])\n",
        "                                 for i in range(len(filter_sizes))\n",
        "    ])\n",
        "    self.fc = nn.Linear(sum(num_filters), classes)\n",
        "    self.drp = nn.Dropout(drop_rate)\n",
        "\n",
        "  def forward(self, batch):\n",
        "\n",
        "    embed = self.embedding(batch)\n",
        "    embed = embed.permute(0, 2, 1) #Conv1D expects the data to be of batch, width, height\n",
        "    convs = [F.relu(conv(embed)) for conv in self.conv1d]\n",
        "    pooled = [F.max_pool1d(conv, kernel_size = conv.shape[2]) for conv in convs] #OP:  (b, num_filters[i], 1)\n",
        "    logits = self.fc(self.drp(torch.cat([pool.squeeze(dim=2) for pool in pooled], dim = 1)))\n",
        "    return logits\n",
        "\n",
        "model = CNN_Text(torch.tensor(embeddings), [2, 3, 4, 5], [5] * 4 )\n",
        "print('The number of trainable parameters are :', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This runs on cuda\n",
            "The number of trainable parameters are : 21041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlot1GT0X53l"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def train_m(model, iterator, optimizer, l):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  model.train()\n",
        "\n",
        "  for inputs, labels in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    preds = model(inputs)\n",
        "    acc = ((preds.ge(0.5).view(-1)) == labels).sum().float() / len(preds)\n",
        "    loss = l(preds.squeeze(1), labels.float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    e_loss += loss.item()\n",
        "    e_acc += acc.item()\n",
        "  return e_loss/len(iterator), e_acc/len(iterator)\n",
        "\n",
        "def evaluate_m(model, iterator, l):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in iterator:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      preds = model(inputs)\n",
        "      loss = l(preds.squeeze(1), labels.float())\n",
        "      acc = ((preds.ge(0.5).view(-1)) == labels).sum().float() / len(preds)\n",
        "      e_loss += loss.item()\n",
        "      e_acc += acc.item()\n",
        "  return e_loss/len(iterator), e_acc/len(iterator)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNBq_T5Ib7Tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d423304f-2a5d-42bd-fb03-50b852f71ed4"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train_m(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate_m(model, test_loader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} / {N_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.564 | Train Acc: 66.05%\n",
            "\t Val. Loss: 0.466 |  Val. Acc: 74.14%\n",
            "Epoch: 02 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.484 | Train Acc: 74.83%\n",
            "\t Val. Loss: 0.411 |  Val. Acc: 78.64%\n",
            "Epoch: 03 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.454 | Train Acc: 76.93%\n",
            "\t Val. Loss: 0.380 |  Val. Acc: 81.28%\n",
            "Epoch: 04 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.434 | Train Acc: 78.21%\n",
            "\t Val. Loss: 0.357 |  Val. Acc: 83.98%\n",
            "Epoch: 05 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.411 | Train Acc: 79.84%\n",
            "\t Val. Loss: 0.333 |  Val. Acc: 84.23%\n",
            "Epoch: 06 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.403 | Train Acc: 80.35%\n",
            "\t Val. Loss: 0.324 |  Val. Acc: 84.69%\n",
            "Epoch: 07 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.395 | Train Acc: 80.42%\n",
            "\t Val. Loss: 0.310 |  Val. Acc: 85.29%\n",
            "Epoch: 08 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.378 | Train Acc: 81.39%\n",
            "\t Val. Loss: 0.297 |  Val. Acc: 86.09%\n",
            "Epoch: 09 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.374 | Train Acc: 82.14%\n",
            "\t Val. Loss: 0.290 |  Val. Acc: 86.78%\n",
            "Epoch: 10 / 10 | Epoch Time: 0m 5s\n",
            "\tTrain Loss: 0.364 | Train Acc: 82.29%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 88.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NeBw_NTmL00"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emFSYv-8mNSH"
      },
      "source": [
        "LABEL_DICT =  {0: 'Normal', 1: 'Sarcastic'}\n",
        "\n",
        "def predict(sentence):\n",
        "  input_tensor = torch.tensor([prepare_data(sentence)]).to(device)\n",
        "  pred = model(input_tensor)\n",
        "  if torch.sigmoid(pred).ge(0.5).item():\n",
        "    print(LABEL_DICT[1])\n",
        "  else:\n",
        "    print(LABEL_DICT[0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93u17KV1nPK3",
        "outputId": "4f62cd3a-3c3d-4f5f-aa1f-dd735af01413"
      },
      "source": [
        "predict('I am lucky not to have this')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
